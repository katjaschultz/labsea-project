{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f1e83c",
   "metadata": {},
   "source": [
    "## Demo Notebook to demonstrate process to run overturning calculation based on Argo float data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62017d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "script_dir = pathlib.Path().parent.absolute()\n",
    "parent_dir = script_dir.parents[0]\n",
    "sys.path.append(str(parent_dir))\n",
    "\n",
    "import xarray as xr\n",
    "from labsea_project import my_readers, writers, plotters, tools\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c904a75",
   "metadata": {},
   "source": [
    "### 1 - Argo data loading and processing\n",
    "First, we fetch Argo data within the Labradror Sea region form https://erddap.ifremer.fr year by year to avoid big files and crashes while loading, this takes some while. Next the data is merged and unnecessary data files are deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f140c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch argo data and save to 'data' directory\n",
    "# this will take a while, so be patient\n",
    "my_readers.fetch_argo_data_per_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7564b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge fetched agro data into one dataset along the profile dimension and delete individual yearly files to save space\n",
    "data_dir = parent_dir / 'data'\n",
    "files = sorted(data_dir.glob('ArgoFetched_*.nc'))\n",
    "ds = xr.open_mfdataset(files, combine='nested', concat_dim='N_PROF', engine=\"netcdf4\")\n",
    "ds.to_netcdf(data_dir / 'LabSea_Argo_2004_2023.nc')\n",
    "\n",
    "print(\"All files successfully merged and saved.\")\n",
    "\n",
    "for file in data_dir.glob('ArgoFetched_*.nc'):\n",
    "    file.unlink()   \n",
    "\n",
    "print(\"All individual yearly files have been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1320ca50",
   "metadata": {},
   "source": [
    "Now we will process the data to select only profiles in range of 75km of the AR7W line\n",
    "and save the result to a new file, delte the original file to save space.\n",
    "The script will generate two nc files, one includes only profiles within 1000dbar isobars in the region, the other also includes some profiles on the shelf. It will aslo generate a plot of the profiles in the region to validate the script ran correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = f'{parent_dir}/scripts/argo_data_processing.py'\n",
    "%run \"{script_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5d7dd",
   "metadata": {},
   "source": [
    "### 2 - Derive gridded composite sections\n",
    "\n",
    "Now we calculate composite sections defining years and months argo data is selected for. For the demo, the months May, June and July are choosen for the decade between 2004 and 2013. First, masks are created for the specified cases and then weighted means are calculated with specified options, e.g the section start and end, the grid spacing and the parameter 'omega' which gives the width of the gaussian curve used for weighting in km. Gridded composites of sepcific volume anomaly, sigma0, SA and CT are saved automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will select profiles and save a mask based on the specified season, and years,\n",
    "# which is then used further to derive gridded sections for the selected case.\n",
    "\n",
    "filename =  parent_dir / \"data/argo_profiles_75kmAR7W_2004_to_2023_1000dB_isobars.nc\"\n",
    "case= '0413_mayjunjul'                                               # case string to identify the case\n",
    "season = [5,6,7]                                                     # indicate months to select for the case\n",
    "years = [2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013] # indicate years to select for the case\n",
    "tools.select_profiles_and_save_masks(filename, case, season, years)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd8124",
   "metadata": {},
   "source": [
    "This script computes a weighted mean of the specific volume anomaly, sigma0, SA and CT from selected profiles.\n",
    "It can handle both Argo and CTD data, applying a Gaussian weighting based on the distance of profiles to grid points.\n",
    "It will interpolate the profiles onto a common vertical grid and compute the weighted averages for each grid point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argo\n",
    "case = '0413_mayjunjul'  # case string to identify the case\n",
    "file_case = '2004_to_2023_1000db_isobars'\n",
    "\n",
    "script_path = parent_dir / \"scripts\" / \"calc_weighted_mean.py\"\n",
    "filename = parent_dir / \"data\" / f\"argo_profiles_75kmAR7W_{file_case}.nc\"\n",
    "mask_profiles_file =  parent_dir / \"data/profile masks\" / f\"mask_{case}.nc\" # set to 'empty' if no mask should be used\n",
    "\n",
    "# Optional arguments\n",
    "spacing_z = 25\n",
    "spacing_x = 10\n",
    "omega = 30.0\n",
    "xstart = 200\n",
    "xend = 860\n",
    "\n",
    "# make sure the output directory exists\n",
    "output_dir = parent_dir / \"data\" / \"weighted data\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = parent_dir / \"data/weighted data\" / f\"weighted_data_{file_case}_{case}_omega{int(omega)}_xstart{str(xstart)}_xend{xend}.npy\"\n",
    "\n",
    "python_executable = sys.executable\n",
    "\n",
    "# Run the script\n",
    "process_w = subprocess.Popen(\n",
    "    [\n",
    "        python_executable, str(script_path),\n",
    "        str(filename),\n",
    "        str(mask_profiles_file),\n",
    "        str(output_file),\n",
    "        \n",
    "        \"--spacing_z\", str(spacing_z),\n",
    "        \"--spacing_x\", str(spacing_x),\n",
    "        \"--omega\", str(omega),\n",
    "        \"--xstart\", str(xstart),\n",
    "        \"--xend\", str(xend),\n",
    "        \"--argo\"\n",
    "    ],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True,\n",
    "    encoding='utf-8'  \n",
    ")\n",
    "\n",
    "# Display output in real-time\n",
    "for line in process_w.stdout:\n",
    "    print(line, end=\"\") \n",
    "    \n",
    "# Display errors in real-time\n",
    "for line in process_w.stderr:\n",
    "    print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a76a1c7",
   "metadata": {},
   "source": [
    "### 3 - Derive overturning transports\n",
    "\n",
    "In this following function a dataset is created loading all the relevant variables for the choosen case, and calculate the absolute geostrophical velocities and overturning transports, saved alltogether in a dataset. $\\textcolor{blue}{mask\\_sigma}$ is a boolean to decide whether values greater than $27.8 \\hspace{0.1cm} kg/m^{3}$ should be excluded from the overturning calculations. Look at the function to see how the variables are derived in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa096d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = '0413_mayjunjul'\n",
    "file_case = '2004_to_2023_1000db_isobars'\n",
    "omega = 30.0\n",
    "xstart = 200\n",
    "xend = 860\n",
    "\n",
    "Ds = writers.create_dataset(case, file_case, omega, xstart, xend, spacing_z=25, spacing_x=10, mask_sigma=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make some plots to visualize the data\n",
    "''' Description of the plot:\n",
    "This plot shows the absolute geostrophic velocity derived from Argo data.\n",
    "black contours represent density contours in 0.02 kg/m^3 intervals.\n",
    "white (labled) contours represent velocity contours in 0.1 m/s intervals.'''\n",
    "\n",
    "plotters.plot_abs_geo_v(Ds, \"Absolute Geostrophic Velocity\", \"xstart200_depth_space\", saving=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Description of the plot:\n",
    "This plot shows the absolute geostrophic velocity derived from Argo data.\n",
    "Dashed line represents pieceswise integrated transport, solid line represents cumulatively integrated transport.'''\n",
    "\n",
    "plotters.plot_overturning_transport(\n",
    "    Ds, \n",
    "    main_label=f\"{case}, xstart={xstart}km\", \n",
    "    main_color=\"mediumorchid\",\n",
    "    title=\"Overturning Transport\",\n",
    "    savepath=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abc11c",
   "metadata": {},
   "source": [
    "To make up for the imbalance in transport (we expect balanced transport for the Labrador Sea in this layer), we force the transport to be zero at 2000m depth by adding a constant velocity to the velocity section. There are two options, first the 'barotropic' option, which is a constant along the complete section and an adjustment only for the eastern 100km. For both, we derive the velocity satisfying the condition of balanced transport and adding it then in the process of deriving adjusted streamfunctions. For plotting purposes, we save them in seperate datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41015e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc adujustment to balance transport in depth space\n",
    "v = Ds['v'].values.copy()\n",
    "xhalf = Ds['xhalf'].values\n",
    "z = Ds['z'].values\n",
    "sigma0half = Ds['sigma0half'].values.copy()\n",
    "\n",
    "# barotropic adj.\n",
    "c0 = tools.find_adjustment_velocity(v, xhalf*1e3, z*-1, onlyEast=False)\n",
    "strf_z_adj0, strf_x_adj0, imbalance_adj0, mask_xa_adj0, pw_trapz_z0, pw_trapz_x_adj0 = tools.derive_strf(v, xhalf*1e3, z*-1, sensitivity=c0, onlyEast=False)\n",
    "Ds['c0'] = c0\n",
    "\n",
    "# declare new dataset to store the results\n",
    "Ds_adj = xr.Dataset(\n",
    "    {\n",
    "        'v': (['z', 'xhalf'], v),\n",
    "        'c0': c0,\n",
    "        'strf_z': (['z'], strf_z_adj0),\n",
    "        'strf_x': (['xhalf'], strf_x_adj0),\n",
    "        'imbalance': imbalance_adj0,\n",
    "        'mask_xa': (['xhalf'], mask_xa_adj0.data),\n",
    "        'piecewise_trapz_z': (['z0'], pw_trapz_z0),\n",
    "        'piecewise_trapz_x': (['x0'], pw_trapz_x_adj0)\n",
    "    },\n",
    "    coords={\n",
    "        'xhalf': ('xhalf', xhalf),\n",
    "        'z': ('z', z),\n",
    "        'z0': ('z0', z[1:]),\n",
    "        'x0': ('x0', xhalf[1:]),\n",
    "    }\n",
    ")\n",
    "\n",
    "# adj. at eastern edge\n",
    "c_east = tools.find_adjustment_velocity(v, xhalf*1e3, z*-1, onlyEast=True)\n",
    "Ds['c_east'] = c_east\n",
    "\n",
    "strf_z_adj_east, strf_x_adj_east, imbalance_adj_east, mask_xa_adj_east, pw_trapz_z_east, pw_trapz_x_adj_east = tools.derive_strf(v, xhalf*1e3, z*-1, sensitivity=c_east, onlyEast=True)\n",
    "\n",
    "\n",
    "# Declare new dataset to store the results\n",
    "Ds_adj_east = xr.Dataset(\n",
    "    {\n",
    "        'v': (['z', 'xhalf'], v),\n",
    "        'c_east': c_east,\n",
    "        'strf_z': (['z'], strf_z_adj_east),\n",
    "        'strf_x': (['xhalf'], strf_x_adj_east),\n",
    "        'imbalance': imbalance_adj_east,\n",
    "        'mask_xa': (['xhalf'], mask_xa_adj_east.data),\n",
    "        'piecewise_trapz_z': (['z0'], pw_trapz_z_east),\n",
    "        'piecewise_trapz_x': (['x0'], pw_trapz_x_adj_east)\n",
    "    },\n",
    "    coords={\n",
    "        'xhalf': ('xhalf', xhalf),\n",
    "        'z': ('z', z),\n",
    "        'z0': ('z0', z[1:]),\n",
    "        'x0': ('x0', xhalf[1:]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all together\n",
    "\n",
    "plotters.plot_overturning_transport(\n",
    "    Ds, \n",
    "    main_label=f\"{case}, xstart={xstart}km\", \n",
    "    main_color=\"mediumorchid\",\n",
    "    extra_lines=[\n",
    "        {'ds': Ds_adj, 'label': 'Barotropic Adjustment', 'color': 'teal'},\n",
    "        {'ds': Ds_adj_east, 'label': 'Eastern Edge Adjustment', 'color': 'orange'}\n",
    "    ],\n",
    "    title=\"Overturning Transport\",\n",
    "    savepath=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796aaeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal transport plot\n",
    "\n",
    "plotters.plot_horizontal_transport(\n",
    "    Ds, \n",
    "    main_label=f\"{case}, xstart={xstart}km\", \n",
    "    main_color=\"mediumorchid\",\n",
    "    extra_lines=[\n",
    "        {'ds': Ds_adj, 'label': 'Barotropic Adjustment', 'color': 'teal'},\n",
    "        {'ds': Ds_adj_east, 'label': 'Eastern Edge Adjustment', 'color': 'orange'}\n",
    "    ],\n",
    "    title=\"Horizontal Transport\",\n",
    "    savepath=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086651d8",
   "metadata": {},
   "source": [
    "#### Density space\n",
    "\n",
    "To determine the transport in density space, we need a mean density depth to depth relation for the purpose of plotting the transport on a scaled depth. For this we will use all profiles available for the selected section. We first calculate composite sections accordingly, and then save the mean density of the section. Then the transport in density space is calculated and plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d03582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate scaled depth\n",
    "file_case = '2004_to_2023_1000db_isobars'\n",
    "case = 'all_data'\n",
    "omega = 30.0\n",
    "xstart = 200\n",
    "xend = 860\n",
    "spacing_z = 25\n",
    "spacing_x = 10\n",
    "\n",
    "script_path = parent_dir / \"scripts\" / \"calc_weighted_mean.py\"\n",
    "filename = parent_dir / \"data\" / f\"argo_profiles_75kmAR7W_{file_case}.nc\"\n",
    "mask_profiles_file =  'empty' # set to 'empty' if no mask should be used, aka all profiles should be used\n",
    "\n",
    "output_file = parent_dir / \"data/weighted data\" / f\"weighted_data_{file_case}_{case}_omega{int(omega)}_xstart{str(xstart)}_xend{xend}.npy\"\n",
    "python_executable = sys.executable\n",
    "\n",
    "# Run the script\n",
    "process_w = subprocess.Popen(\n",
    "    [\n",
    "        python_executable, str(script_path),\n",
    "        str(filename),\n",
    "        str(mask_profiles_file),\n",
    "        str(output_file),\n",
    "        \n",
    "        \"--spacing_z\", str(spacing_z),\n",
    "        \"--spacing_x\", str(spacing_x),\n",
    "        \"--omega\", str(omega),\n",
    "        \"--xstart\", str(xstart),\n",
    "        \"--xend\", str(xend),\n",
    "        \"--argo\"\n",
    "    ],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    text=True,\n",
    "    encoding='utf-8'  \n",
    ")\n",
    "\n",
    "# Display output in real-time\n",
    "for line in process_w.stdout:\n",
    "    print(line, end=\"\") \n",
    "    \n",
    "# Display errors in real-time\n",
    "for line in process_w.stderr:\n",
    "    print(line, end=\"\")\n",
    "\n",
    "# load the saved data again and calculate/save the mean sigma0\n",
    "specvol_anom_argo, sigma0_argo, SA_argo, CT_argo = np.load(parent_dir / f\"data/weighted data/weighted_data_{file_case}_{case}_omega{int(omega)}_xstart{str(xstart)}_xend{xend}.npy\")\n",
    "mean_sigma0 = np.nanmean(sigma0_argo, axis=1)\n",
    "np.save(parent_dir / f\"data/mean_sigma0_{file_case}_{case}_omega{int(omega)}_xstart{str(xstart)}_xend{xend}.npy\", mean_sigma0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mean_sigma0 (not necessary if you just calculated it)\n",
    "mean_sigma0 = np.load(parent_dir / f\"data/mean_sigma0_{file_case}_all_data_omega{int(omega)}_xstart{str(xstart)}_xend{xend}.npy\")\n",
    "\n",
    "# derive transport in density space, define sigma_bins (griding of transport in density space / bins)\n",
    "step = 0.005\n",
    "sigma_bins = np.linspace(27.2, 27.8, np.int64((27.8-27.2)/step)+1)\n",
    "\n",
    "# default: no adj.\n",
    "Q0, Q = tools.derive_transport_in_density_space(v, sigma0half, sigma_bins)\n",
    "Q0_adj, Q_adj = tools.derive_transport_in_density_space(v, sigma0half, sigma_bins, sensitivity=c0)    \n",
    "Q0_east, Q_east = tools.derive_transport_in_density_space(v, sigma0half, sigma_bins, sensitivity=c_east, onlyEast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot transport in density space\n",
    "\n",
    "scaled_depth = np.interp(sigma_bins, mean_sigma0, z)\n",
    "case = '0413_mayjunjul'\n",
    "\n",
    "plotters.plot_density_space_transport(\n",
    "    Q0, Q, scaled_depth,\n",
    "    main_label=\"transport raw\", main_color=\"mediumorchid\",\n",
    "    extra_lines=[\n",
    "        {'Q': Q0_adj, 'Q_cum': Q_adj, 'label': 'transport barotropic adj.', 'color': 'teal'},\n",
    "        {'Q': Q0_east, 'Q_cum': Q_east, 'label': 'transport adj. east', 'color': 'darkorange'}\n",
    "    ],\n",
    "    densities=[27.64, 27.66, 27.68, 27.7, 27.72, 27.74, 27.76, 27.78, 27.8],\n",
    "    sigma_bins=sigma_bins, mean_sigma0=mean_sigma0, z=z,\n",
    "    title=f\"{case}, xstart = {xstart}km\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labsea-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
